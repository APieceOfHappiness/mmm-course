{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACW1C6syhxIE"
      },
      "outputs": [],
      "source": [
        "! pip install yt-dlp ffmpeg-python decord"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install qwen-vl-utils[decord]==0.0.8"
      ],
      "metadata": {
        "id": "yyjog8aDV4wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")"
      ],
      "metadata": {
        "id": "iqc82h0RBXKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yvbThbPfkLN"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "from yt_dlp.utils import download_range_func\n",
        "# from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "import os.path as osp\n",
        "import ffmpeg\n",
        "\n",
        "# Список видео и параметры нарезки\n",
        "videos = [\n",
        "    # (ссылка, старт_сек, продолжительность, название)\n",
        "    (\"https://youtu.be/E8gmARGvPlI\", 21, 20, \"christmas\"),\n",
        "    (\"https://youtu.be/9Xvp7_KETrE\", 183, 20, \"photocamera\"),\n",
        "    (\"https://youtu.be/EiUy8aJJKOQ\", 707, 20, \"lecture\"),\n",
        "    # (\"https://youtu.be/9bZkp7q19f0\", 24, 20, \"gangam_style\"),\n",
        "    # (\"https://youtu.be/XU75_nskEMY\", 29, 20, \"ot_vinta\"),\n",
        "    (\"https://youtu.be/hSK_f1L0-xE\", 51, 20, \"radiotapok\"),\n",
        "    # (\"https://youtu.be/cR0ou0U3m2g\", 21, 30, \"ryba\"),\n",
        "    (\"https://youtu.be/n8i53TtQ6IQ\", 35, 25, \"mass_effect\"),\n",
        "    (\"https://youtu.be/sDruogVbfRg\", 314, 30, \"naruto\"),\n",
        "    # (\"https://youtu.be/N03iShqFXmE\", 125, 53, \"zhukov\"),\n",
        "]\n",
        "\n",
        "OUTPUT_FOLDER = \"videos\"\n",
        "OUTPUT_FILES = {}\n",
        "\n",
        "def cut_video(start, end, input_file, output_file):\n",
        "    ffmpeg.input(input_file, ss=start, to=end).output(output_file, c='copy').run(overwrite_output=True)\n",
        "\n",
        "def download_and_cut(youtube_url, start_t, duration, out_file):\n",
        "    \"\"\"Скачивает видео и нарезает нужный фрагмент\"\"\"\n",
        "\n",
        "    print(\"Downloading video\")\n",
        "\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "    download_name = osp.join(OUTPUT_FOLDER, f\"full_{out_file}.mp4\")\n",
        "\n",
        "    cut_border = 5\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'mp4/best',\n",
        "        'outtmpl': download_name,\n",
        "        'quiet': True,\n",
        "        'noplaylist': True,\n",
        "        'download_ranges': download_range_func(None, [(start_t - cut_border, start_t + duration)])\n",
        "    }\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([youtube_url])\n",
        "\n",
        "    print(\"Cutting video\")\n",
        "\n",
        "    output_file = osp.join(OUTPUT_FOLDER, f\"{out_file}.mp4\")\n",
        "    cut_video(cut_border, cut_border + duration, download_name, output_file)\n",
        "    os.remove(download_name)\n",
        "    # Обрезка необходима чтобы убрать черные кадры в начале, обращующиеся при скачивании\n",
        "    OUTPUT_FILES[out_file] = output_file\n",
        "\n",
        "\n",
        "for idx, (url, start, dur, name) in enumerate(videos, 1):\n",
        "    print(f\"Processing video {name} ({idx}/{len(videos)})...\")\n",
        "    try:\n",
        "        download_and_cut(url, start, dur, name)\n",
        "        print(f\"Video {name} ({idx}/{len(videos)}) is processed\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url}: {e}\")\n",
        "\n",
        "print(\"All videos processed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "osp.abspath(OUTPUT_FILES['christmas'])"
      ],
      "metadata": {
        "id": "d7BVs70OYpSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Qwen2VLForConditionalGeneration, Qwen2_5_VLForConditionalGeneration, Qwen3VLForConditionalGeneration, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import gc\n",
        "\n",
        "\n",
        "class ModelOutputBuilder:\n",
        "    def __init__(self, type_model, model):\n",
        "        self.model_name = model\n",
        "        self.type_model = type_model\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.model = self.type_model.from_pretrained(self.model_name, torch_dtype=\"auto\", device_map=\"auto\")\n",
        "        self.processor = AutoProcessor.from_pretrained(self.model_name)\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args, **kwargs):\n",
        "        del self.model\n",
        "        del self.processor\n",
        "        gc.collect()\n",
        "\n",
        "    def __call__(self, video, prompt):\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"video\",\n",
        "                        \"video\": f\"file://{osp.abspath(OUTPUT_FILES[video])}\",\n",
        "                        \"max_pixels\": 360 * 420,\n",
        "                        \"fps\": 1.0,\n",
        "                    },\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                ],\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        text = self.processor.apply_chat_template(\n",
        "            messages, tokenize=False, add_generation_prompt=True\n",
        "        )\n",
        "        image_inputs, video_inputs = process_vision_info(messages)\n",
        "        inputs = self.processor(\n",
        "            text=[text],\n",
        "            images=image_inputs,\n",
        "            videos=video_inputs,\n",
        "            padding=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        inputs = inputs.to(\"cuda\")\n",
        "\n",
        "\n",
        "        generated_ids = self.model.generate(**inputs, max_new_tokens=4000)\n",
        "        generated_ids_trimmed = [\n",
        "            out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
        "        ]\n",
        "        output_text = self.processor.batch_decode(\n",
        "            generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "        )\n",
        "\n",
        "        return output_text[0]"
      ],
      "metadata": {
        "id": "wJ4aEC6hoau5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with ModelOutputBuilder(Qwen2_5_VLForConditionalGeneration, \"Qwen/Qwen2.5-VL-3B-Instruct\") as model:\n",
        "    print(model(\"christmas\", \"Посмотри на видео и ответь, что на нем изображено\"))"
      ],
      "metadata": {
        "id": "QvUmHu9RqpuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "del model\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "3vqzmIp-xssa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shlex, subprocess, base64\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def ensure_ffmpeg():\n",
        "    from shutil import which\n",
        "    if which(\"ffmpeg\") is None:\n",
        "        # на Colab обычно уже есть; оставляю на всякий случай\n",
        "        !apt -y -qq update >/dev/null\n",
        "        !apt -y -qq install ffmpeg >/dev/null\n",
        "\n",
        "def reencode_to_h264(src_path: str|Path) -> Path:\n",
        "    ensure_ffmpeg()\n",
        "    src = Path(src_path)\n",
        "    assert src.exists(), f\"File not found: {src}\"\n",
        "    dst = src.with_name(src.stem + \"_h264.mp4\")\n",
        "    if dst.exists() and dst.stat().st_size > 0:\n",
        "        return dst\n",
        "    cmd = (\n",
        "        f'ffmpeg -y -i {shlex.quote(str(src))} '\n",
        "        f'-vcodec libx264 -pix_fmt yuv420p -profile:v baseline -level 3.0 '\n",
        "        f'-movflags +faststart -an {shlex.quote(str(dst))} -loglevel error'\n",
        "    )\n",
        "    subprocess.run(cmd, shell=True, check=True)\n",
        "    assert dst.exists() and dst.stat().st_size > 0, \"Re-encode failed: output empty\"\n",
        "    return dst\n",
        "\n",
        "def show_video(path: str|Path, width: int = 560, force_reencode: bool = True):\n",
        "    p = Path(path)\n",
        "    assert p.exists(), f\"Input path missing: {p}\"\n",
        "    if force_reencode:\n",
        "        p = reencode_to_h264(p)\n",
        "    # читаем и встраиваем как base64 — обходим капризы Video(...)\n",
        "    with open(p, \"rb\") as f:\n",
        "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "    html = f\"\"\"\n",
        "    <video width=\"{width}\" controls playsinline>\n",
        "      <source src=\"data:video/mp4;base64,{b64}\" type=\"video/mp4\">\n",
        "      Your browser does not support the video tag.\n",
        "    </video>\n",
        "    <div style=\"font-size:12px;color:#666\">File: {p} • {p.stat().st_size/1024:.1f} KB</div>\n",
        "    \"\"\"\n",
        "    return HTML(html)\n",
        "\n",
        "# Пример:\n",
        "display(show_video(OUTPUT_FILES['christmas'], width=320, force_reencode=True))"
      ],
      "metadata": {
        "id": "mVAxnvIFunHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "srkHf6vNBTFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from textwrap import fill\n",
        "\n",
        "\n",
        "def print_f(text):\n",
        "    print(fill(text, width=120))\n",
        "\n",
        "\n",
        "def compare_answers(prompt):\n",
        "    models = [\n",
        "        (Qwen2VLForConditionalGeneration, \"Qwen/Qwen2-VL-2B-Instruct\"),\n",
        "        (Qwen2_5_VLForConditionalGeneration, \"Qwen/Qwen2.5-VL-3B-Instruct\"),\n",
        "        (Qwen3VLForConditionalGeneration, \"Qwen/Qwen3-VL-4B-Instruct\"),\n",
        "    ]\n",
        "\n",
        "    answers = {}\n",
        "\n",
        "    for model_type, model_name in models:\n",
        "        print_f(f\"Started processing by model: {model_name}\")\n",
        "        with ModelOutputBuilder(model_type, model_name) as model:\n",
        "            for name in tqdm(list(OUTPUT_FILES.keys())):\n",
        "                answer = model(name, prompt)\n",
        "                val_t = answers.get(name, {})\n",
        "                val_t[model_name.split(\"/\")[-1]] = answer\n",
        "                answers[name] = val_t\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    for name, answer in answers.items():\n",
        "        print_f(f\"Video: {name}\")\n",
        "        display(show_video(OUTPUT_FILES[name], width=320, force_reencode=True))\n",
        "\n",
        "        print()\n",
        "        print_f(f\"Q: {prompt}\")\n",
        "\n",
        "        for model_name, model_answer in answer.items():\n",
        "            print_f(f\"A {model_name}: {model_answer}\")\n",
        "\n",
        "        print()\n",
        "        print_f(\"---------------------------------\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "LWozOKD3wHvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_answers(\"Describe the video\")"
      ],
      "metadata": {
        "id": "cB6nN4Aa-8qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_answers(\"Опиши видео\")"
      ],
      "metadata": {
        "id": "oUzAcxJhPuu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_answers(\"Опиши видео на русском языке\")"
      ],
      "metadata": {
        "id": "eW-yUu2vPsJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_answers(\"Сколько людей находятся на видео?\")"
      ],
      "metadata": {
        "id": "2YqcBaMUPnvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_answers(\"Назови жанр видео\")"
      ],
      "metadata": {
        "id": "SJwAZiRzP0-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_answers(\"Какой жанр у данного видеофрагмента:\\n1. Фильм\\n2. Трейлер видеоигры\\n3. Мультфильм\\n4. Лекция\\n5. Другое\\nОтветь одной цифрой\")"
      ],
      "metadata": {
        "id": "IXno7zFnP6pf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}